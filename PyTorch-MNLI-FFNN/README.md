# PyTorch Feedforward Neural Network for MNLI Dataset
## Introduction
This Jupyter Notebook contains an implementation for a standard feedforward neural network that is used to classify the sentence pairs contained in the MNLI dataset. This was a project for a Neural Networks course, however all code was written solely by me and was not provided as a part of the assignment. The project specification was only extend a pre-extisting model and train the extension to classify the MNLI dataset.

## The MNLI Dataset
The MNLI dataset (https://huggingface.co/datasets/multi_nli) contains approximately 433K samples, where each sample has its input (a pair of sentences) and desired output (a label indicating the relationship between the two sentences).Each sentence pair consists of a premise sentence and hypothesis sentence. Premises are image captions sourced from Flickr30K while hypothesis were generated by crowd-sourced annotators. The
annotators were shown a premise and asked to generate a hypothesis that was in entailment, neutral or in contradiction to the premise. These three relationships are the three labels assigned to each sentence pair in the dataset. The labels are indicated with an integer: 0 for entailment, 1 for neutral and 2 for contradiction.

## The Implemented Model Extension
The base model chosen for extension is the pre-trained Sentence-BERT Transformer designed by UPK Labs (https://paperswithcode.com/paper/sentence-bert-sentence-embeddings-using). This is a model that converts sentences into fixed length (384 components) sentence embeddings. The paper showed that Sentence-BERT embeddings performed on average 15-20% better than standard BERT and GloVe embeddings in STS tasks (based on spearman rank of correlation of cosine similarity against gold semantic similarity).

The use of sentence embeddings allows a simpler neural network to be designed for the classification problem, as opposed to having the network learn to parse sentences from scratch. It is following this, that the feed forward network was designed to the following specifications:

![Model Diagram](./doc/model_diagram.png?raw=true "Model Diagram")

More information on the specific model design, dataset preprocessing and training process are all detailed in the release.ipynb notebook.

## Results
The model's best performance is approximately 73% accuracy, compared to the average 91.4% achieved by SOTA models (https://paperswithcode.com/sota/natural-language-inference-on-multinli). Detailed Results can be found in the Model Results and Evaluation Section in release.ipynb.

This accuracy seems to be its upper bound as variations in the number of hidden layers, learning rate and loss functions still resulted in the same maximum accuracy. This upper bound could be caused by the fixed length of Sentence-BERT embeddings. Some premise-hypothesis pairs have significantly different word counts, meaning that the same vector size is used to represent significantly different amounts of information. This could be a limit to the semantic understanding contained within the embeddings and hence a limit on the learning of the model.

Possible steps to improve the model performance could be an improvement in the sentence embeddings fed into the model. As covered above, it could be a limitation to the semantic understanding the model requires to infer the premise-hypothesis relationships. The model can be trained using sentence embeddings generated by other SOTA models, and the best performing embedding can be selected for the final model.

## Other Information and Credits
The folder `sentence-transformer` contains the source code for the pretrained Sentence-BERT transformer. This was taken from the UPK Labs Git Repository (https://github.com/UKPLab/sentence-transformers) to allow the model code to be tested and run locally.



